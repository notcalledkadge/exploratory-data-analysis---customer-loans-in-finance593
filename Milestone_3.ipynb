{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from db_utils import RDSDatabaseConnector, load_credentials\n",
    "from scipy.stats import skew\n",
    "from data_transform import DataTransform\n",
    "from dataframe_info import DataFrameInfo\n",
    "from dataframe_transform import DataFrameTransform, Plotter \n",
    "\n",
    "# Step 1: Load credentials and initialize database connector\n",
    "credentials_path = \"/Users/ks/exploratory_data_analysis/credentials.yaml\"\n",
    "credentials = load_credentials(credentials_path)\n",
    "rds_connector = RDSDatabaseConnector(credentials)\n",
    "rds_connector.ignition_switch()\n",
    "\n",
    "# Step 2: Extract data from the database\n",
    "query = \"SELECT * FROM loan_payments\"\n",
    "data = rds_connector.extract_data(query)\n",
    "\n",
    "# Step 3: Initialize and perform data transformations\n",
    "transformer = DataTransform(data)\n",
    "\n",
    "# Specify columns to transform\n",
    "numeric_columns = [\n",
    "    'loan_amount', 'funded_amount', 'funded_amount_inv', 'int_rate', 'dti', 'inq_last_6mths',\n",
    "    'mths_since_last_delinq', 'mths_since_last_record', 'open_accounts', 'total_accounts', 'out_prncp',\n",
    "    'out_prncp_inv', 'total_payment', 'total_payment_inv', 'total_rec_prncp', 'total_rec_late_fee',\n",
    "    'recoveries', 'collection_recovery_fee', 'last_payment_amount', 'collections_12_mths_ex_med', 'mths_since_last_major_derog'\n",
    "]\n",
    "datetime_columns = [\n",
    "    'issue_date', 'earliest_credit_line', 'last_payment_date', 'next_payment_date', 'last_credit_pull_date'\n",
    "]\n",
    "categorical_columns = [\n",
    "    'id', 'member_id', 'term', 'grade', 'sub_grade', 'employment_length', 'home_ownership',\n",
    "    'verification_status', 'loan_status', 'purpose', 'application_type', 'payment_plan', 'delinq_2yrs'\n",
    "]\n",
    "symbol_cleaning_columns = []  # Add columns if needed\n",
    "symbols_to_remove = \"?!$%\"\n",
    "\n",
    "# Perform necessary transformations\n",
    "transformer.convert_to_numeric(numeric_columns)\n",
    "transformer.convert_to_datetime(datetime_columns)\n",
    "transformer.convert_to_categorical(categorical_columns)\n",
    "if symbol_cleaning_columns:\n",
    "    transformer.clean_symbols(symbol_cleaning_columns, symbols=symbols_to_remove)\n",
    "\n",
    "# Get the transformed data\n",
    "transformed_data = transformer.get_transformed_data()\n",
    "\n",
    "# Step 4: Save the transformed data to CSV for further analysis\n",
    "output_csv_path = \"/Users/ks/exploratory_data_analysis/output_data/transformed_data.csv\"\n",
    "transformed_data.to_csv(output_csv_path, index=False)\n",
    "print(f\"Data saved to CSV successfully at {output_csv_path}.\")\n",
    "\n",
    "# Step 5: Perform EDA using DataFrameInfo class\n",
    "df_info = DataFrameInfo(transformed_data)\n",
    "df_info.summary()\n",
    "\n",
    "# Step 6: Further EDA transformations and visualizations\n",
    "df_transformer = DataFrameTransform(transformed_data)\n",
    "\n",
    "# Plot the NULL values before handling\n",
    "plotter = Plotter(df_transformer.get_transformed_data())\n",
    "plotter.plot_null_values(title=\"Null Values Before Handling\")\n",
    "\n",
    "# Check and print the amount of NULL values\n",
    "null_info_before = df_transformer.check_nulls()\n",
    "\n",
    "# Drop columns with more than 50% NULL values\n",
    "columns_to_drop = null_info_before[null_info_before['Null Percentage'] > 50].index.tolist()\n",
    "df_transformer.drop_columns(columns_to_drop)\n",
    "\n",
    "# Impute remaining NULL values with median\n",
    "df_transformer.impute_missing(strategy='median')\n",
    "\n",
    "# Plot NULL values after handling\n",
    "plotter.plot_null_values(title=\"Null Values After Handling\")\n",
    "\n",
    "# Check and print amount of NULL values again\n",
    "df_transformer.check_nulls()\n",
    "\n",
    "# Identify and remove outliers\n",
    "outlier_columns = ['loan_amount', 'int_rate', 'dti', 'total_rec_prncp', 'total_rec_late_fee']  # Example columns\n",
    "df_transformer.remove_outliers(outlier_columns)\n",
    "\n",
    "# Re-visualize data after removing outliers\n",
    "plotter.plot_boxplots(outlier_columns, title=\"Boxplots of Numeric Columns After Outlier Removal\")\n",
    "\n",
    "# Save transformed DataFrame\n",
    "transformed_output_csv_path = \"/Users/ks/exploratory_data_analysis/output_data/transformed_data_outliers_removed.csv\"\n",
    "df_transformer.get_transformed_data().to_csv(transformed_output_csv_path, index=False)\n",
    "print(f\"Transformed data with outliers removed saved to CSV successfully at {transformed_output_csv_path}.\")\n",
    "\n",
    "# Compute correlation matrix\n",
    "numeric_data = transformed_data.select_dtypes(include=np.number)\n",
    "correlation_matrix = numeric_data.corr()\n",
    "\n",
    "# Visualize correlation matrix as a heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=.5)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Identify highly correlated columns and decide which ones to remove\n",
    "correlation_threshold = 0.7\n",
    "highly_correlated_columns = set()\n",
    "\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i):\n",
    "        if abs(correlation_matrix.iloc[i, j]) > correlation_threshold:\n",
    "            colname = correlation_matrix.columns[i]\n",
    "            highly_correlated_columns.add(colname)\n",
    "\n",
    "print(\"Highly correlated columns:\")\n",
    "print(highly_correlated_columns)\n",
    "\n",
    "# Remove highly correlated columns\n",
    "transformed_data.drop(columns=highly_correlated_columns, inplace=True)\n",
    "\n",
    "# Save the updated DataFrame\n",
    "transformed_output_csv_path = \"/Users/ks/exploratory_data_analysis/output_data/no_highly_correlated_data.csv\"\n",
    "transformed_data.to_csv(transformed_output_csv_path, index=False)\n",
    "print(f\"Transformed data with outliers removed saved to CSV successfully at {transformed_output_csv_path}.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
